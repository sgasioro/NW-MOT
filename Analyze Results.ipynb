{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "import gradoptics as optics\n",
    "from gradoptics.integrator import HierarchicalSamplingIntegrator\n",
    "from ml.siren import Siren\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115fadb",
   "metadata": {},
   "source": [
    "## Same scene setup as in training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d57838",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_source = optics.LightSourceFromDistribution(optics.AtomCloud(phi=0.1, w0=0.01, k_fringe=2*np.pi/(0.001),\n",
    "                                                                   position=[0., 0., 0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a35651",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "in_features = 3\n",
    "hidden_features = 256\n",
    "hidden_layers = 3\n",
    "out_features = 1\n",
    "\n",
    "model = Siren(in_features, hidden_features, hidden_layers, out_features,\n",
    "              outermost_linear=True, outermost_linear_activation=nn.ReLU()).double().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bfe59",
   "metadata": {},
   "source": [
    "## Set up grid to sample\n",
    "1/sqrt(2) is the edge of the cube that falls within a sphere of radius 1 (to avoid corner effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_side = 100\n",
    "bound = 1/np.sqrt(2.)\n",
    "grid = torch.cartesian_prod(torch.linspace(-bound, bound, n_side),\n",
    "                            torch.linspace(-bound, bound, n_side),\n",
    "                            torch.linspace(-bound, bound, n_side)).cuda().double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a05133",
   "metadata": {},
   "source": [
    "## Load model and evaluate densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f07459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = '/sdf/group/magis/sgaz/NW-MOT/models/'\n",
    "f_pattern = 'model_*_NW_MOT_all_cameras_long.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "n_checkpoints = len(glob(dir_name+f_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6af9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = (n_checkpoints-1)*500\n",
    "print(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70864d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100**3\n",
    "with torch.no_grad():\n",
    "    fname = f_pattern.replace(\"*\", \"{last}\").format(last=last)\n",
    "    model.load_state_dict(torch.load(dir_name+fname))\n",
    "    densities = []\n",
    "    grid_batches = grid.split(batch_size)\n",
    "    for grid_batch in tqdm(grid_batches):\n",
    "        densities.append(model(grid_batch)[0].cpu())\n",
    "    densities = torch.cat(densities).reshape((n_side, n_side, n_side))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad=0.03\n",
    "n_side = 100\n",
    "real_grid = torch.cartesian_prod(torch.linspace(-bound*rad, bound*rad, n_side),\n",
    "                            torch.linspace(-bound*rad, bound*rad, n_side),\n",
    "                            torch.linspace(-bound*rad, bound*rad, n_side)).cuda().double()\n",
    "pdf_vals = light_source.pdf(real_grid).reshape((n_side, n_side, n_side)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(2, 4, figsize=(8,4))\n",
    "\n",
    "ax[0, 0].text(0.9, 0.5, \"Reconstructed\", ha='right', fontsize=14)\n",
    "ax[0, 0].axis('off')\n",
    "\n",
    "ax[1, 0].text(0.9, 0.5, \"True\", ha='right', fontsize=14)\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "ax[0, 1].imshow(densities.sum(dim=0).T, origin=\"lower\")\n",
    "ax[0, 1].set_title('Sum x', fontsize=14)\n",
    "ax[0, 1].axis('off')\n",
    "\n",
    "ax[0, 2].imshow(densities.sum(dim=1).T, origin=\"lower\")\n",
    "ax[0, 2].set_title('Sum y', fontsize=14)\n",
    "ax[0, 2].axis('off')\n",
    "\n",
    "ax[0, 3].imshow(densities.sum(dim=2).T, origin=\"lower\")\n",
    "ax[0, 3].set_title('Sum z', fontsize=14)\n",
    "ax[0, 3].axis('off')\n",
    "\n",
    "ax[1, 1].imshow(pdf_vals.sum(dim=0).T, origin=\"lower\")\n",
    "ax[1, 1].axis('off')\n",
    "\n",
    "ax[1, 2].imshow(pdf_vals.sum(dim=1).T, origin=\"lower\")\n",
    "ax[1, 2].axis('off')\n",
    "\n",
    "ax[1, 3].imshow(pdf_vals.sum(dim=2).T, origin=\"lower\")\n",
    "ax[1, 3].axis('off')\n",
    "plt.tight_layout()\n",
    "save_name = fname.replace('.pt', '.png').replace('model', 'marginal')\n",
    "plt.savefig(save_name, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969de518",
   "metadata": {},
   "source": [
    "## You can really do whatever analysis you want\n",
    "\n",
    "Marginals are as above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e30d20",
   "metadata": {},
   "source": [
    "mrcfile lets you load a 3D representation with, e.g., ChimeraX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcfile\n",
    "filename = fname.replace('.pt', '.mrc').replace('model', 'test_mrc')\n",
    "with mrcfile.new(dir_name+filename, overwrite=True) as mrc:\n",
    "    mrc.set_data(densities.float().cpu().detach().numpy())\n",
    "    mrc.voxel_size = 2*rad*bound/grid.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c9804",
   "metadata": {},
   "source": [
    "We can make a training animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_densities = []\n",
    "with torch.no_grad():\n",
    "    for n_iter in tqdm(np.arange(0, n_checkpoints*500, 500)):\n",
    "        model.load_state_dict(torch.load(f_pattern.replace(\"*\", \"{n_iter}\").format(n_iter=n_iter)))\n",
    "        densities = model(grid)[0].reshape((n_side, n_side, n_side)).cpu()\n",
    "        all_densities.append(densities.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803aeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from celluloid import Camera\n",
    "fig, ax = plt.subplots(2, 4, figsize=(8,4))\n",
    "camera = Camera(fig)\n",
    "\n",
    "for i in range(len(all_densities)):\n",
    "    ax[0, 0].text(0.9, 0.5, \"Reconstructed\", ha='right', fontsize=14)\n",
    "    ax[0, 0].axis('off')\n",
    "\n",
    "    ax[1, 0].text(0.9, 0.5, \"True\", ha='right', fontsize=14)\n",
    "    ax[1, 0].axis('off')\n",
    "\n",
    "    ax[0, 1].imshow(all_densities[i].sum(dim=0).T, origin=\"lower\")\n",
    "    ax[0, 1].set_title('Sum x', fontsize=14)\n",
    "    ax[0, 1].axis('off')\n",
    "\n",
    "    ax[0, 2].imshow(all_densities[i].detach().sum(dim=1).T, origin=\"lower\")\n",
    "    ax[0, 2].set_title('Sum y', fontsize=14)\n",
    "    ax[0, 2].axis('off')\n",
    "\n",
    "    ax[0, 3].imshow(all_densities[i].sum(dim=2).T, origin=\"lower\")\n",
    "    ax[0, 3].set_title('Sum z', fontsize=14)\n",
    "    ax[0, 3].axis('off')\n",
    "    \n",
    "\n",
    "    ax[1, 1].imshow(pdf_vals.sum(dim=0).T, origin=\"lower\")\n",
    "    ax[1, 1].axis('off')\n",
    "\n",
    "    ax[1, 2].imshow(pdf_vals.sum(dim=1).T, origin=\"lower\")\n",
    "    ax[1, 2].axis('off')\n",
    "\n",
    "    ax[1, 3].imshow(pdf_vals.sum(dim=2).T, origin=\"lower\")\n",
    "    ax[1, 3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    camera.snap()\n",
    "\n",
    "animation = camera.animate()\n",
    "save_name = fname.replace('.pt', '.mp4').replace('model', 'training')\n",
    "animation.save(save_name)\n",
    "\n",
    "#from IPython.display import HTML\n",
    "#HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee407d1",
   "metadata": {},
   "source": [
    "Or we can render images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_objects = pickle.load(open(\"NW_mot_scene_components.pkl\", \"rb\"))\n",
    "targets = pickle.load(open(\"NW_mot_images.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce39446",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_mask = torch.ones(targets.shape[1:], dtype=torch.bool)\n",
    "sel_mask[:250] = 0\n",
    "sel_mask[1750:] = 0\n",
    "sel_mask[:, 1500:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ede38",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = 0.03\n",
    "obj_pos = (0, 0, 0)\n",
    "\n",
    "light_source = optics.LightSourceFromNeuralNet(model, optics.BoundingSphere(radii=rad, \n",
    "                                                                     xc=obj_pos[0], yc=obj_pos[1], zc=obj_pos[2]),\n",
    "                                        rad=rad, x_pos=obj_pos[0], y_pos=obj_pos[1], z_pos=obj_pos[2])\n",
    "scene_train = optics.Scene(light_source)\n",
    "\n",
    "for obj in scene_objects:\n",
    "    scene_train.add_object(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adb211",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list = [obj for obj in scene_train.objects if type(obj) == optics.Sensor]\n",
    "lens_list = [obj for obj in scene_train.objects if type(obj) == optics.PerfectLens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e292c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradoptics.integrator import HierarchicalSamplingIntegrator\n",
    "integrator = HierarchicalSamplingIntegrator(64, 64, stratify = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_size = 200000//40\n",
    "\n",
    "    im_all = []\n",
    "    camera_list = torch.arange(len(targets))\n",
    "    for data_id in camera_list:\n",
    "        print(data_id.item())\n",
    "        sensor_here = sensor_list[data_id]\n",
    "        lens_here = lens_list[data_id]\n",
    "\n",
    "        h_here, w_here = sensor_list[data_id].resolution\n",
    "\n",
    "        idxs_all = torch.cartesian_prod(torch.arange(h_here//2, -h_here//2, -1), \n",
    "                                        torch.arange(w_here//2, -w_here//2, -1))\n",
    "\n",
    "        idxs_all = idxs_all[sel_mask.flatten()]\n",
    "\n",
    "        all_pixels = torch.arange(0, len(idxs_all))\n",
    "        all_pixels = all_pixels.split(batch_size)\n",
    "\n",
    "        intensities_all = []\n",
    "        for pixels_batch in tqdm(all_pixels):\n",
    "            batch_pix_x = idxs_all[pixels_batch, 0]\n",
    "            batch_pix_y = idxs_all[pixels_batch, 1]\n",
    "\n",
    "\n",
    "            intensities_batch = optics.ray_tracing.ray_tracing.render_pixels(sensor_here, \n",
    "                                                          lens_here, \n",
    "                                                         scene_train, scene_train.light_source, 1, 5, \n",
    "                                                         batch_pix_x, batch_pix_y,\n",
    "                                                         integrator, device='cuda',max_iterations=6)\n",
    "            intensities_all.append(intensities_batch.clone())\n",
    "        im = torch.cat(intensities_all).reshape((1500, 1500)).cpu()\n",
    "        im_all.append(im.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13737bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563db39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
